# ДЗ № 3 "Машинное обучение в продакшене", MADE, весна 2021.

## 1. Деплой Airflow
Развертывание локального Airflow под Win10 + WSL2 + Docker Desktop имеет определенные сложности (см. подробности далее), поэтому набор команд имеет более сложный вид. По идее это также должно работать под Linux, но у меня не было возможности проверить.

1.1. Сборка базового образа  
Сначала необходимо перейти в папку airflow-ml-base и оттуда запустить команду  
```docker build . -t airflow-ml-base:latest```  

1.2. Запуск Airflow  
Далее надо вернуться в папку проекта и запустить команду  
```docker-compose up --build```  

1.3. Запуск интерфейса  
В браузере необходимо ввести  
```http://localhost:8080/```  

1.4. Корректное завершение работы  
В CLI нажать CTRL + C, затем ввести команду  
```docker-compose down```  

1.5. Тестирование  
```pytest -v```  


## 2. Работа с переменными окружения  
2.1. Для корректной работы с alert перед запуском Airflow необходимо указать (Win10):  
```
set GMAIL_USERNAME=<user_name>
set GMAIL_PASSWORD=<password>
```
После этого они корректно подхватятся в docker-compose.yml. При использовании для алертов электронной почты google также необходимо в политиках аккаунта разрешить небезопасные приложения, в противном случае сообщения будут заблокированы.  

2.2. Для возможности использования переменных, созданных в UI Airflow, я сделал следующее:  
- Сгенерировал FERNET_KEY с помощью скрипта misc/fernet_code_generation.py  
- Полученное значение вписал в docker-compose.yml  
```- AIRFLOW__CORE__FERNET_KEY='<Значение FERNET_KEY, выданное скриптом>'```  

2.3. Для использования Airflow variables для указания пути к модели я расширил команду в разделе init файла docker-compose.yml следующей строкой:  
```&& airflow variables set PROD_DIR data/model/2021-06-04```  
Это позволяет при развертывании Airflow сразу инициализировать переменную PROD_DIR начальным значением. Впоследствии его можно поменять на более подходящее в UI Airflow.  

2.4. Для корректной работы сенсоров необходимо расширить команду в разделе init файла docker-compose.yml, дописав после добавления админа следующее:  
```&& airflow connections add fs_default --conn-type fs```  


## 3. Особенности сборки под Win10
3.1. При попытке стартовать систему командой docker compose up --build под Win10+WSL2 вылетала ошибка. По-видимому, это объяснялось тем, что образы, перечисленные в docker-compose.yml, собирались в рандомном порядке, и ошибка появлялась тогда, когда докер пытался собрать дочерний образ раньше родительского.
Решить проблему удалось следующим образом:  
- Из папки, в которой лежал родительсктй образ, собирался базовый контейнер  
```docker build . -t airflow-ml-base:latest```  
- Из основной папки с проектом запускалась команда  
```docker-compose up --build```  

3.2. При использовании в Win10 стандартной команды docker compose (без дефиса) Airflow выдавал ошибку при запуске DockerOperator. Поэтому пришлось использловать команду docker-compose (с дефисом).  

3.3. Docker Desktop под Win10 + WSL2 видимо некорректно работает с кэшем, т.к. очень часто отладка кода не приводила к изменениям в логах ошибки. Поэтому при модификации кода проекта приходилось полностью удалять все образы и контейнеры с глубокой очисткой кэша - это всегда помогало.  


## Самооценка

+ Поднимите airflow локально, используя docker compose 
+ Реализуйте dag, который генерирует данные для обучения модели (5 баллов)
+ Реализуйте dag, который обучает модель еженедельно, используя данные за текущий день. В Вашем пайплайне должно быть как минимум 4 стадии (10 баллов) 
+ Реализуйте dag, который использует модель ежедневно (5 баллов)
+ Реализуйте сенсоры на то, что данные готовы для дагов тренировки и обучения (3 доп. балла)
+ Все даги реализованы только с помощью DockerOperator (10 баллов)
+ Протестируйте Ваши даги (5 баллов) 
+ Настройте alert в случае падения дага (3 доп. балла)
+ Проведите самооценку (1 доп. балл)
+ Итого: 42 балла
