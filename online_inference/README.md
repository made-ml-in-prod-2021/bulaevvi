# ДЗ № 2 "Машинное обучение в продакшене", MADE, весна 2021.

## Установка

Если нет тестового окружения, создать виртуальное окружение:
```
conda create -n $env_name python=3.8
```
Активировать окружение, в котором будете проводить тестирование проекта:
```
conda activate $env_name
```
В активированном окружении установить необходимые пакеты
```
pip install -r requirements.txt
```

## Project Organization

    ├── requests
    │   ├── make_request.py    <- Скрипт, делающий запросы к серверу.
    │   └── requests.csv       <- Файл, из которого формируются запросы.
    │
    ├── tests
    │   └── test_app.py        <- Тест для /predict.
    │
    ├── app.py                 <- inference модели в виде rest-сервиса.
    │
    ├── Dockerfile             <- Dockerfile-файл для сборки контейнера.
    │
    ├── model.pkl              <- Сериализованная обученная модель.
    │
    ├── README.md              <- README с описанием деталей проекта.
    │
    └── requirements.txt       <- Описание зависимостей.

## Оптимизация размера docker image
Изначально я добавил rest-сервис к проекту, сделанному в ДЗ №1. Но получилась достаточно сложная структура, которую было сложно отлаживать. Docker-файл содержал примерно в два раза больше строк, чем текущая версия. Впоследствии я решил отказаться от этой идеи и пришел к простой и прозрачной структуре, которая есть сейчас: всего 8 файлов и 2 папки для удобства.
Кроме того, в соотвествии с Лекцией 4 я организовал Docker-файл по принципу часто меняющиеся команды - вниз, редко - наверх. Это позволило ускорить процессы сборки образа в разы.

## Работа с Docker

### Сборка образа
cd online_inference
docker build -t bulaevvi/online_inference:v1 .

### Запуск образа на локальной машине
docker run -p 8000:8000 bulaevvi/online_inference:v1

### Загрузка образа в репозиторий
docker push bulaevvi/online_inference:v1

## Самооценка

+ Назовите ветку homework2, положите код в папку online_inference 
+ Оберните inference вашей модели в rest сервис(FastAPI), должен быть endpoint /predict (3 балла)
+ Напишите тест для /predict  (3 балла) 
+ Напишите скрипт, который будет делать запросы к вашему сервису (2 балла)
+ Напишите dockerfile, соберите на его основе образ и запустите локально контейнер(docker build, docker run), внутри контейнера должен запускать сервис, написанный в предущем пункте, закоммитьте его, напишите в readme корректную команду сборки (4 балла)
+ Оптимизируйте размер docker image (3 доп балла) (опишите в readme.md что вы предприняли для сокращения размера и каких результатов удалось добиться)
+ Опубликуйте образ в https://hub.docker.com/, используя docker push (вам потребуется зарегистрироваться) (2 балла)
+ Напишите в readme корректные команды docker pull/run, которые должны привести к тому, что локально поднимется на inference ваша модель. Убедитесь, что вы можете протыкать его скриптом из пункта 3 (1 балл)
+ проведите самооценку (1 доп балл)
+ создайте пулл-реквест и поставьте label -- hw2
+ Итого: 19 баллов
